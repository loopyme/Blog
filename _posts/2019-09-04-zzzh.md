---
layout:     post
title: 周志华教授的研究兴趣画像
subtitle: 使用Jupyter notebook
date:       2019-09-04
author:     Loopy
header-img: img/home-bg-geek.jpg
catalog: true
tags:
    - Fun
    - AI
---

本文从[周志华教授的简历网站](https://cs.nju.edu.cn/zhouzh/)出发，收集周教授的研究兴趣相关数据，并进行分析画像。

> 本文档为文字版本，若需查看带源码的notebook,请前往[此处](http://file.loopy.tech/share/zzh-portrait.html)

## A. 概览
> 简历网站首页： I have wide research interests, mainly including artificial intelligence, machine learning, data mining, pattern recognition, evolutionary computation and multimedia retrieval, among which machine learning and data mining are my core research areas. I am particularly interested in the problem of how to enable computing machines to handle "ambiguity".

整理一下，他的```研究兴趣```大致在：
 - 人工智能
 - **机器学习**
 - **数据挖掘**
 - 模式识别
 - 进化计算
 - 多媒体检索

接下来找下他的[文章](https://cs.nju.edu.cn/zhouzh/zhouzh.files/publication/publication_toc.htm)，来组一个数据集，以定量的预测下他的研究兴趣。

## B. 设计数据集
> M. Xu, Y.-F. Li, and Z.-H. Zhou. Robust multi-label learning with PRO loss. IEEE Transactions on Knowledge and Data Engineering, in press.

每条文章信息由四个数据段构成，再扩展两个特征：文章的分类，文章的链接，一共六个特征组成原始数据集.

数据集样本示例：

|分类|作者|标题|刊物或会议|时间|链接|
|---|---|---|---|---|---|
|Multi-Label Learning|M. Xu, Y.-F. Li, and Z.-H. Zhou.|Robust multi-label learning with PRO loss.|IEEE Transactions on Knowledge and Data Engineering,|in press.|https://cs.nju.edu.cn/zhouzh/zhouzh.files/publication/tkde19proloss.pdf|

这样的数据集看起来还不错，接下来写个脚本把其他样本收集整理好。再耐心的洗一下数据.(由于网站格式特别乱，部分数据还是没有洗干净)



<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>分类</th>
      <th>作者</th>
      <th>标题</th>
      <th>刊物或会议</th>
      <th>时间</th>
      <th>链接</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>Multi-Label Learning</td>
      <td>M. Xu, Y.-F. Li, andZ.-H. Zhou.</td>
      <td>Robust multi-label learning with PRO loss</td>
      <td>IEEE Transactions on Knowledge and Data Engine...</td>
      <td>in press</td>
      <td>https://cs.nju.edu.cn/zhouzh/zhouzh.files/publ...</td>
    </tr>
    <tr>
      <td>1</td>
      <td>Multi-Label Learning</td>
      <td>T.-Z. Wang, S.-J. Huang, and Z.-H. Zhou.</td>
      <td>Towards identifying causal relation between in...</td>
      <td>Proceedings of the 19th SIAM International Con...</td>
      <td>2019</td>
      <td>https://cs.nju.edu.cn/zhouzh/zhouzh.files/publ...</td>
    </tr>
    <tr>
      <td>2</td>
      <td>Multi-Label Learning</td>
      <td>S.-J. Huang, W. Gao, and Z.-H. Zhou.</td>
      <td>Fast multi-instance multi-label learning</td>
      <td>IEEE Transactions on Pattern Analysis and Mach...</td>
      <td>in press</td>
      <td>https://cs.nju.edu.cn/zhouzh/zhouzh.files/publ...</td>
    </tr>
    <tr>
      <td>3</td>
      <td>Multi-Label Learning</td>
      <td>S.-Y. Li, Y. Jiang, N. V. Chawla, andZ.-H. Zhou.</td>
      <td>Multi-label learning from crowds</td>
      <td>IEEE Transactions on Knowledge and Data Engine...</td>
      <td>2019</td>
      <td>https://cs.nju.edu.cn/zhouzh/zhouzh.files/publ...</td>
    </tr>
    <tr>
      <td>4</td>
      <td>Multi-Label Learning</td>
      <td>Y. Zhu, K. M. Ting, andZ.-H. Zhou.</td>
      <td>Multi-label learning with emerging new labels</td>
      <td>IEEE Transactions on Knowledge and Data Engine...</td>
      <td>2018</td>
      <td>https://cs.nju.edu.cn/zhouzh/zhouzh.files/publ...</td>
    </tr>
    <tr>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <td>529</td>
      <td>Miscellaneous</td>
      <td>Z.-H. Zhou.</td>
      <td>Three perspectives of data mining&lt;/font&gt;</td>
      <td>Artificial Intelligence</td>
      <td>2003</td>
      <td>https://cs.nju.edu.cn/zhouzh/zhouzh.files/publ...</td>
    </tr>
    <tr>
      <td>530</td>
      <td>Miscellaneous</td>
      <td>Z.-H. Zhou and S.-F. Chen.</td>
      <td>Evolving fault-tolerant neural networks&lt;/font&gt;</td>
      <td>Neural Computing &amp;amp; Applications</td>
      <td>2003</td>
      <td>https://cs.nju.edu.cn/zhouzh/zhouzh.files/publ...</td>
    </tr>
    <tr>
      <td>531</td>
      <td>Miscellaneous</td>
      <td>Z.-H. Zhou.</td>
      <td>Review on &lt;i&gt;Data Mining: Concepts and Techniq...</td>
      <td>IEEE Transactions on Neural Networks</td>
      <td>2002</td>
      <td>https://cs.nju.edu.cn/zhouzh/zhouzh.files/publ...</td>
    </tr>
    <tr>
      <td>532</td>
      <td>Miscellaneous</td>
      <td>Z.-H. Zhou, S.-F. Chen, and Z.-Q. Chen.</td>
      <td>Improving tolerance of neural networks against...</td>
      <td>Proceedings of the INNS-IEEE International Joi...</td>
      <td>2001</td>
      <td>https://cs.nju.edu.cn/zhouzh/zhouzh.files/publ...</td>
    </tr>
    <tr>
      <td>533</td>
      <td>Miscellaneous</td>
      <td>Z.-H. Zhou, S. Chen, and Z. Chen.</td>
      <td>FANNC: A fast adaptive neural network classifi...</td>
      <td>Knowledge and Information Systems</td>
      <td>2000</td>
      <td>https://cs.nju.edu.cn/zhouzh/zhouzh.files/publ...</td>
    </tr>
  </tbody>
</table>
<p>534 rows × 6 columns</p>
</div>



## C. 特征处理

为了预测研究兴趣，对数据集做一些处理。

1. 从`作者`衍生出`作者排名` (即周志华教授是第几作者)
2. 把`链接`丢掉(在本文中暂时放弃对文章内容的分析)

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>分类</th>
      <th>作者</th>
      <th>标题</th>
      <th>刊物或会议</th>
      <th>时间</th>
      <th>作者排名</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>Multi-Label Learning</td>
      <td>M. Xu, Y.-F. Li, andZ.-H. Zhou.</td>
      <td>Robust multi-label learning with PRO loss</td>
      <td>IEEE Transactions on Knowledge and Data Engine...</td>
      <td>in press</td>
      <td>3</td>
    </tr>
    <tr>
      <td>1</td>
      <td>Multi-Label Learning</td>
      <td>T.-Z. Wang, S.-J. Huang, and Z.-H. Zhou.</td>
      <td>Towards identifying causal relation between in...</td>
      <td>Proceedings of the 19th SIAM International Con...</td>
      <td>2019</td>
      <td>3</td>
    </tr>
    <tr>
      <td>2</td>
      <td>Multi-Label Learning</td>
      <td>S.-J. Huang, W. Gao, and Z.-H. Zhou.</td>
      <td>Fast multi-instance multi-label learning</td>
      <td>IEEE Transactions on Pattern Analysis and Mach...</td>
      <td>in press</td>
      <td>3</td>
    </tr>
    <tr>
      <td>3</td>
      <td>Multi-Label Learning</td>
      <td>S.-Y. Li, Y. Jiang, N. V. Chawla, andZ.-H. Zhou.</td>
      <td>Multi-label learning from crowds</td>
      <td>IEEE Transactions on Knowledge and Data Engine...</td>
      <td>2019</td>
      <td>4</td>
    </tr>
    <tr>
      <td>4</td>
      <td>Multi-Label Learning</td>
      <td>Y. Zhu, K. M. Ting, andZ.-H. Zhou.</td>
      <td>Multi-label learning with emerging new labels</td>
      <td>IEEE Transactions on Knowledge and Data Engine...</td>
      <td>2018</td>
      <td>3</td>
    </tr>
    <tr>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <td>529</td>
      <td>Miscellaneous</td>
      <td>Z.-H. Zhou.</td>
      <td>Three perspectives of data mining&lt;/font&gt;</td>
      <td>Artificial Intelligence</td>
      <td>2003</td>
      <td>1</td>
    </tr>
    <tr>
      <td>530</td>
      <td>Miscellaneous</td>
      <td>Z.-H. Zhou and S.-F. Chen.</td>
      <td>Evolving fault-tolerant neural networks&lt;/font&gt;</td>
      <td>Neural Computing &amp;amp; Applications</td>
      <td>2003</td>
      <td>1</td>
    </tr>
    <tr>
      <td>531</td>
      <td>Miscellaneous</td>
      <td>Z.-H. Zhou.</td>
      <td>Review on &lt;i&gt;Data Mining: Concepts and Techniq...</td>
      <td>IEEE Transactions on Neural Networks</td>
      <td>2002</td>
      <td>1</td>
    </tr>
    <tr>
      <td>532</td>
      <td>Miscellaneous</td>
      <td>Z.-H. Zhou, S.-F. Chen, and Z.-Q. Chen.</td>
      <td>Improving tolerance of neural networks against...</td>
      <td>Proceedings of the INNS-IEEE International Joi...</td>
      <td>2001</td>
      <td>1</td>
    </tr>
    <tr>
      <td>533</td>
      <td>Miscellaneous</td>
      <td>Z.-H. Zhou, S. Chen, and Z. Chen.</td>
      <td>FANNC: A fast adaptive neural network classifi...</td>
      <td>Knowledge and Information Systems</td>
      <td>2000</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
<p>534 rows × 6 columns</p>
</div>



## D. 数据集分析

### 概览

[分析报告](http://file.loopy.tech/share/zzh-portrait-dataset.html)见此处

### 时间维度

各年份发表文章数


<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>2000</th>
      <th>2001</th>
      <th>2002</th>
      <th>2003</th>
      <th>2004</th>
      <th>2005</th>
      <th>2006</th>
      <th>2007</th>
      <th>2008</th>
      <th>2009</th>
      <th>2010</th>
      <th>2011</th>
      <th>2012</th>
      <th>2013</th>
      <th>2014</th>
      <th>2015</th>
      <th>2016</th>
      <th>2017</th>
      <th>2018</th>
      <th>2019</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Face Recognition</td>
      <td>1.0</td>
      <td>NaN</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>5.0</td>
      <td>6.0</td>
      <td>10.0</td>
      <td>2.0</td>
      <td>3.0</td>
      <td>3.0</td>
      <td>2.0</td>
      <td>1.0</td>
      <td>NaN</td>
      <td>1.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>1.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <td>Miscellaneous</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>2.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>1.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <td>Ensemble Learning</td>
      <td>NaN</td>
      <td>1.0</td>
      <td>2.0</td>
      <td>4.0</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>7.0</td>
      <td>4.0</td>
      <td>5.0</td>
      <td>9.0</td>
      <td>6.0</td>
      <td>7.0</td>
      <td>6.0</td>
      <td>6.0</td>
      <td>6.0</td>
      <td>3.0</td>
      <td>NaN</td>
      <td>3.0</td>
      <td>5.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <td>Computer-Aided Medical Diagnosis</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>1.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <td>Improving Comprehensibility</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>1.0</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <td>Multi-Instance Learning</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>1.0</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>3.0</td>
      <td>1.0</td>
      <td>5.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>6.0</td>
      <td>3.0</td>
      <td>4.0</td>
      <td>NaN</td>
      <td>1.0</td>
      <td>5.0</td>
      <td>NaN</td>
      <td>2.0</td>
    </tr>
    <tr>
      <td>Image Retrieval</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>4.0</td>
      <td>2.0</td>
      <td>1.0</td>
      <td>5.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>2.0</td>
      <td>NaN</td>
      <td>1.0</td>
      <td>NaN</td>
      <td>1.0</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <td>Metric Learning, Dimensionality Reduction and Feature Selection</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>1.0</td>
      <td>3.0</td>
      <td>5.0</td>
      <td>1.0</td>
      <td>3.0</td>
      <td>6.0</td>
      <td>3.0</td>
      <td>2.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>NaN</td>
      <td>1.0</td>
      <td>4.0</td>
      <td>1.0</td>
      <td>NaN</td>
      <td>1.0</td>
    </tr>
    <tr>
      <td>Multi-View Learning</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>1.0</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>3.0</td>
      <td>1.0</td>
      <td>4.0</td>
      <td>4.0</td>
      <td>3.0</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>3.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>NaN</td>
      <td>1.0</td>
    </tr>
    <tr>
      <td>Semi-Supervised and Active Learning</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>1.0</td>
      <td>3.0</td>
      <td>2.0</td>
      <td>6.0</td>
      <td>1.0</td>
      <td>8.0</td>
      <td>5.0</td>
      <td>7.0</td>
      <td>6.0</td>
      <td>10.0</td>
      <td>2.0</td>
      <td>5.0</td>
      <td>5.0</td>
      <td>4.0</td>
      <td>3.0</td>
      <td>2.0</td>
    </tr>
    <tr>
      <td>Multi-Label Learning</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>3.0</td>
      <td>3.0</td>
      <td>7.0</td>
      <td>8.0</td>
      <td>3.0</td>
      <td>3.0</td>
      <td>1.0</td>
      <td>5.0</td>
      <td>5.0</td>
      <td>2.0</td>
    </tr>
    <tr>
      <td>Bioinformatics</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>2.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>3.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>3.0</td>
      <td>1.0</td>
      <td>2.0</td>
      <td>NaN</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <td>Cost-Sensitive and Class-Imbalance Learning</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>4.0</td>
      <td>NaN</td>
      <td>2.0</td>
      <td>1.0</td>
      <td>4.0</td>
      <td>1.0</td>
      <td>2.0</td>
      <td>4.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>3.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <td>Structure Learning and Clustering</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>1.0</td>
      <td>3.0</td>
      <td>1.0</td>
      <td>3.0</td>
      <td>5.0</td>
      <td>9.0</td>
      <td>5.0</td>
      <td>5.0</td>
      <td>10.0</td>
      <td>5.0</td>
      <td>2.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <td>Theoretical Aspects of Evolutionary Computation</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>1.0</td>
      <td>NaN</td>
      <td>2.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>2.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>4.0</td>
      <td>3.0</td>
      <td>2.0</td>
      <td>3.0</td>
      <td>NaN</td>
    </tr>
    <tr>
      <td>Web Search and Mining</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>3.0</td>
      <td>3.0</td>
      <td>1.0</td>
      <td>2.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <td>Software Mining</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>1.0</td>
    </tr>
    <tr>
      <td>Crowdsourcing Learning</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>2.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <td>Logic Learning</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>2.0</td>
      <td>1.0</td>
    </tr>
  </tbody>
</table>
</div>


![png](https://github.com/loopyme/loopyme.github.io/blob/master/_posts/pic/2019-09-04/output_11_1.png)


```Ensemble Learning``` 很具有代表性，抓出来分析作者排名


<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>2000</th>
      <th>2001</th>
      <th>2002</th>
      <th>2003</th>
      <th>2004</th>
      <th>2005</th>
      <th>2006</th>
      <th>2007</th>
      <th>2008</th>
      <th>2009</th>
      <th>2010</th>
      <th>2011</th>
      <th>2012</th>
      <th>2013</th>
      <th>2014</th>
      <th>2015</th>
      <th>2016</th>
      <th>2017</th>
      <th>2018</th>
      <th>2019</th>
    </tr>
    <tr>
      <th>作者排名</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>1</td>
      <td>NaN</td>
      <td>1.0</td>
      <td>2.0</td>
      <td>4.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>3.0</td>
      <td>1.0</td>
      <td>NaN</td>
      <td>5.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>NaN</td>
      <td>1.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>1.0</td>
      <td>NaN</td>
      <td>1.0</td>
    </tr>
    <tr>
      <td>2</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>1.0</td>
      <td>NaN</td>
      <td>1.0</td>
      <td>2.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>3.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>3.0</td>
      <td>1.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>3.0</td>
      <td>NaN</td>
    </tr>
    <tr>
      <td>3</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>1.0</td>
      <td>3.0</td>
      <td>NaN</td>
      <td>2.0</td>
      <td>3.0</td>
      <td>2.0</td>
      <td>4.0</td>
      <td>3.0</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>3.0</td>
      <td>NaN</td>
      <td>2.0</td>
      <td>1.0</td>
      <td>NaN</td>
    </tr>
    <tr>
      <td>4</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>2.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>1.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>1.0</td>
      <td>NaN</td>
    </tr>
    <tr>
      <td>5</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>1.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>2.0</td>
      <td>NaN</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <td>6</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>1.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <td>8</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>1.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
</div>



![png](https://github.com/loopyme/loopyme.github.io/blob/master/_posts/pic/2019-09-04/output_14_1.png)


在前期大多为一作，后期二三作增多而一作减少

## 兴趣维度


![png](https://github.com/loopyme/loopyme.github.io/blob/master/_posts/pic/2019-09-04/output_17_1.png)


<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>兴趣占比</th>
    </tr>
    <tr>
      <th>分类</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Computer-Aided Medical Diagnosis</td>
      <td>0.5618%</td>
    </tr>
    <tr>
      <td>Software Mining</td>
      <td>0.7491%</td>
    </tr>
    <tr>
      <td>Logic Learning</td>
      <td>0.9363%</td>
    </tr>
    <tr>
      <td>Crowdsourcing Learning</td>
      <td>1.1236%</td>
    </tr>
    <tr>
      <td>Miscellaneous</td>
      <td>1.3109%</td>
    </tr>
    <tr>
      <td>Improving Comprehensibility</td>
      <td>1.3109%</td>
    </tr>
    <tr>
      <td>Bioinformatics</td>
      <td>2.4345%</td>
    </tr>
    <tr>
      <td>Web Search and Mining</td>
      <td>2.4345%</td>
    </tr>
    <tr>
      <td>Image Retrieval</td>
      <td>4.1199%</td>
    </tr>
    <tr>
      <td>Cost-Sensitive and Class-Imbalance Learning</td>
      <td>4.3071%</td>
    </tr>
    <tr>
      <td>Theoretical Aspects of Evolutionary Computation</td>
      <td>4.6816%</td>
    </tr>
    <tr>
      <td>Multi-View Learning</td>
      <td>6.1798%</td>
    </tr>
    <tr>
      <td>Metric Learning, Dimensionality Reduction and Feature Selection</td>
      <td>6.1798%</td>
    </tr>
    <tr>
      <td>Face Recognition</td>
      <td>6.9288%</td>
    </tr>
    <tr>
      <td>Multi-Instance Learning</td>
      <td>8.2397%</td>
    </tr>
    <tr>
      <td>Multi-Label Learning</td>
      <td>9.9251%</td>
    </tr>
    <tr>
      <td>Structure Learning and Clustering</td>
      <td>9.9251%</td>
    </tr>
    <tr>
      <td>Semi-Supervised and Active Learning</td>
      <td>13.6704%</td>
    </tr>
    <tr>
      <td>Ensemble Learning</td>
      <td>14.9813%</td>
    </tr>
  </tbody>
</table>
</div>



最后，画张词云图吧

![png](https://github.com/loopyme/loopyme.github.io/blob/master/_posts/pic/2019-09-04/output_20_1.png)


以上只是所有历史的兴趣统计，周志华老师的现在的研究兴趣需要做一定的修正，例如近几年在`Crowdsourcing Learning`和`Logic Learning`领域，表现出较高的文章产出，但由于两个领域较为新兴，历史统计受到一定影响．

以后可以尝试完成的工作：
1. 通过超链接下载文章，分词统计等处理后，进一步丰满数据集
1. 尝试进行时序预测，估计未来周志华老师的研究兴趣

> 本文档为文字版本，若需查看带源码的notebook,请前往[此处](http://file.loopy.tech/share/zzh-portrait.html)
